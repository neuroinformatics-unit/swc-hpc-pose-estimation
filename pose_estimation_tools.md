# Pose estimation

A non-exhaustive list of tools for pose estimation (in a broader sense). For each tool a short description is given, as well as links to the corresponding paper, GitHub repository, and documentation (if available).

* [DeepLabCut](http://www.mackenziemathislab.org/deeplabcut) is an efficient method for 2D and 3D markerless pose estimation based on transfer learning with deep neural networks. [Paper1](https://www.nature.com/articles/s41593-018-0209-y) | [Paper2](https://www.nature.com/articles/s41592-022-01443-0) | [GitHub](https://github.com/DeepLabCut/DeepLabCut)
* [SLEAP](https://sleap.ai/) is a deep-learning based framework for multi-animal pose tracking. It can be used to track any type or number of animals and includes an advanced labeling/training GUI for active learning and proofreading. [Paper](https://www.nature.com/articles/s41592-022-01426-1) | [GitHub](https://github.com/talmolab/sleap)
* [TRex](https://trex.run/): is a fast multi-animal tracking system with markerless identification, and 2D estimation of posture and visual fields. [Paper](https://elifesciences.org/articles/64000) | [GitHub](https://github.com/mooch443/trex)
* [DANNCE](https://github.com/spoonsso/dannce/) (3-Dimensional Aligned Neural Network for Computational Ethology) is a CNN that calculates the 3D positions of user-defined anatomical landmarks on behaving animals from videos taken at multiple angles. The key innovation of DANNCE compared to existing approaches for 2D keypoint detection in animals is that the network is fully 3D, so that it can learn about 3D image features and how cameras and landmarks relate to one another in 3D space. [GitHub](https://github.com/spoonsso/dannce/)
* [OpenPose](https://github.com/CMU-Perceptual-Computing-Lab/openpose) has represented the first real-time multi-person system to jointly detect human body, hand, facial, and foot keypoints (in total 135 keypoints) on single images. [GitHub](https://github.com/CMU-Perceptual-Computing-Lab/openpose)
* [DeepPoseKit](https://github.com/jgraving/deepposekit) is a deep learning toolkit for pose estimation and tracking. [Paper](https://elifesciences.org/articles/47994) | [GitHub](https://github.com/jgraving/deepposekit)
* [DeepLabCut-live](https://github.com/DeepLabCut/DeepLabCut-live) allows you to run DeepLabCut pose estimation inference in real time, for closed-loop experiments. [GitHub](https://github.com/DeepLabCut/DeepLabCut-live) | [Paper](https://elifesciences.org/articles/61909) | [GitHub-GUI](https://github.com/DeepLabCut/DeepLabCut-live-GUI)
* [DeepLabStream](https://github.com/SchwarzNeuroconLab/DeepLabStream) is a Python based multi-purpose tool that enables the realtime tracking and manipulation of animals during ongoing experiments. It was orginally adapted from DeepLabCut and expanded on its core capabilities, but is now able to utilize a variety of different network architectures for online pose estimation. DeepLabStream's core feature is the utilization of real-time tracking to orchestrate closed-loop experiments. It's capabilities range from simple region of interest (ROI) based triggers to headdirection or behavior dependent stimulation, including online classification (SiMBA, B-SOID). [GitHub](https://github.com/SchwarzNeuroconLab/DeepLabStream) | [Paper](https://www.nature.com/articles/s42003-021-01654-9)
* [FastTrack](https://www.fasttrack.sh/) is a cross-platform application designed to track multiple objects in video recording. [GitHub](https://github.com/FastTrackOrg/FastTrack) | [Paper](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008697) | [Docs](https://www.fasttrack.sh/docs/intro/)
* [FaceMap](https://github.com/MouseLand/facemap) is a matlab/Python GUI for unsupervised video analysis of rodent behavior (capable of processing multiple camera views)
* [Anipose](https://anipose.readthedocs.io/en/latest/) is an open-source toolkit for robust, markerless 3D tracking of animal behavior from multiple camera views. It leverages the machine learning toolbox DeepLabCut to track keypoints in 2D, then triangulates across camera views to estimate 3D pose. [Paper](https://www.sciencedirect.com/science/article/pii/S2211124721011797?via%3Dihub) | [GitHub](https://github.com/lambdaloop/anipose) | [Documentation](https://anipose.readthedocs.io/en/latest/)
* [FreiPose](https://lmb.informatik.uni-freiburg.de/projects/freipose/): a Deep Learning __C++__ Framework for Precise Animal Motion Capture in 3D Spaces. [Paper](https://www.biorxiv.org/content/10.1101/2020.02.27.967620v1) | [GitHub](https://github.com/lmb-freiburg/FreiPose)
* [DeepBehavior](https://github.com/aarac/DeepBehavior) is a deep learning __matlab__ toolbox for automated analysis of animal and human behavior imaging data. [GitHub](https://github.com/aarac/DeepBehavior) | [Paper](https://www.frontiersin.org/articles/10.3389/fnsys.2019.00020/full)
* [DeepFly3D](https://github.com/NeLy-EPFL/DeepFly3D) is a deep learning-based approach for 3D limb and appendage tracking in tethered, adult Drosophila. [Paper](https://elifesciences.org/articles/48571) | [GitHub](https://github.com/NeLy-EPFL/DeepFly3D)
* [OptiFlex](https://github.com/saptera/OptiFlex) - Multi-Frame Animal Pose Estimation Combining Deep Learning With Optical Flow. [Paper](https://www.frontiersin.org/articles/10.3389/fncel.2021.621252/full) | [GitHub](https://github.com/saptera/OptiFlex)
* [idtracker.ai](https://idtrackerai.readthedocs.io/en/latest/) allows to track groups of up to 100 unmarked animals from videos recorded in laboratory conditions. [GitLab](https://gitlab.com/polavieja_lab/idtrackerai) | [Paper](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1007354)